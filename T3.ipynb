{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "exitosas = pd.read_csv('data/transacciones_exitosas.csv', low_memory=False)\n",
    "fallidas = pd.read_csv('data/transacciones_fallidas.csv')\n",
    "evaluacion = pd.read_csv('data/transacciones_evaluación.csv')\n",
    "\n",
    "# Eliminar fila con mal formato\n",
    "exitosas = exitosas.drop(148541)\n",
    "\n",
    "# Añadir etiquetas a los datos\n",
    "exitosas['label'] = 0\n",
    "fallidas['label'] = 1\n",
    "\n",
    "# Combinar datos exitosos y fallidos\n",
    "datos = pd.concat([exitosas, fallidas], ignore_index=True)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop(columns=['label'])\n",
    "y = datos['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Llenar valores NaN con 0 (u otro método como media o mediana de la columna)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo y los parámetros para GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "}\n",
    "\n",
    "# GridSearchCV para selección de modelos\n",
    "grid = GridSearchCV(model, params, cv=5, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'RandomForestClassifier: f1 Score = {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar datos de entrenamiento y prueba\n",
    "X_combined = np.vstack((X_train, X_test))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Entrenar el mejor modelo con todos los datos disponibles\n",
    "final_model = best_model\n",
    "final_model.fit(X_combined, y_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir probabilidades de falla en el conjunto de evaluación\n",
    "X_evaluacion = evaluacion.drop(columns=['identificador'])  # Asegúrate de ajustar esto según tu archivo de evaluación\n",
    "X_evaluacion = scaler.transform(X_evaluacion)\n",
    "predicciones = final_model.predict_proba(X_evaluacion)[:, 1]\n",
    "\n",
    "# Seleccionar las 200 transacciones con mayor probabilidad de falla\n",
    "evaluacion['probabilidad_falla'] = predicciones\n",
    "top_200 = evaluacion.nlargest(200, 'probabilidad_falla')['identificador']\n",
    "\n",
    "# Guardar los identificadores de las 200 transacciones seleccionadas\n",
    "top_200.to_csv('data/top_200_transacciones_fallidas.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
