{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12be42c5",
   "metadata": {},
   "source": [
    "<head>\n",
    "<b><center>CIENCIA DE DATOS</center>\n",
    "\n",
    "<center>TALLER 3</center>\n",
    "<center>2024-1</center>\n",
    "\n",
    "<center>Profesor: Gabriel Jara </center><br>\n",
    "<center>Integrantes: Fernando Salgado, Cristián González</center><br>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9457d5f",
   "metadata": {},
   "source": [
    "Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab49fc7",
   "metadata": {},
   "source": [
    "Carga Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fef1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "exitosas = pd.read_csv('data/transacciones_exitosas.csv',low_memory=False)\n",
    "fallidas = pd.read_csv('data/transacciones_fallidas.csv')\n",
    "evaluacion = pd.read_csv('data/transacciones_evaluación.csv')\n",
    "\n",
    "# Eliminar fila con mal formato\n",
    "exitosas = exitosas.drop(148541)\n",
    "\n",
    "\n",
    "# Añadir etiquetas a los datos\n",
    "exitosas['label'] = 0\n",
    "fallidas['label'] = 1\n",
    "\n",
    "# Combinar datos exitosos y fallidos\n",
    "datos = pd.concat([exitosas, fallidas], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9fd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y etiquetas\n",
    "X = datos.drop(columns=['label'])\n",
    "y = datos['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56e3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 (or use another method like column mean or median)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Optionally, check and remove or impute infinite values\n",
    "# This is just a placeholder step; actual implementation may vary based on your data\n",
    "X_train = X_train.replace([np.inf, -np.inf], 0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Now you can safely scale your data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9927b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    # 'XGBClassifier': XGBClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LogisticRegression': {'C': [0.1, 1, 10]},\n",
    "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    # 'XGBClassifier': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "# GridSearchCV para selección de modelos\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    grid = GridSearchCV(models[model_name], params[model_name], cv=5, scoring='roc_auc')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "print(\"fin seleccion de modelo\")\n",
    "# Evaluar modelos\n",
    "for model_name in best_models:\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'{model_name}: ROC Score = {roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec68366d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'XGBClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Seleccionar el mejor modelo basado en la métrica de evaluación\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mbest_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXGBClassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Suponiendo que XGBClassifier fue el mejor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con todos los datos disponibles\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_all \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'XGBClassifier'"
     ]
    }
   ],
   "source": [
    "# Seleccionar el mejor modelo basado en la métrica de evaluación\n",
    "best_model = best_models['SVC']  # Suponiendo que XGBClassifier fue el mejor\n",
    "\n",
    "# Entrenar el modelo con todos los datos disponibles\n",
    "X_all = scaler.fit_transform(X)\n",
    "best_model.fit(X_all, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6436b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir probabilidades en el conjunto de evaluación\n",
    "X_eval = scaler.transform(evaluacion)\n",
    "probs = best_model.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "# Seleccionar las 200 transacciones con mayor probabilidad de ser fallidas\n",
    "evaluacion['probabilidad_fallida'] = probs\n",
    "top_200 = evaluacion.nlargest(200, 'probabilidad_fallida')\n",
    "\n",
    "# Guardar los identificadores de las transacciones seleccionadas\n",
    "top_200_ids = top_200.index + 1  # Asumiendo que el índice empieza en 0 y queremos ID de 1 a 1000\n",
    "top_200_ids.to_csv('inspeccionar.csv', index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
